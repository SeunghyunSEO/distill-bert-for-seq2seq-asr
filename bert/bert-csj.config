[model]
hidden_size = 512
num_hidden_layers = 6
num_attention_heads = 8
intermediate_size = 3072
max_position_embeddings = 256

[data]
train_path = ../data/csj/csj.id.bert.train.s256
train_size = 125132

[vocab]
unk_id = 1
mask_id = 4
vocab_size = 7521

[log]
log_path = ./log/bert.csj.log
log_step = 100

[save]
save_prefix = ./checkpoints/bert.csj
save_epoch = 1

[train]
# model_path = ./checkpoints/bert.bccwj.network.epoch50
model_path = ./checkpoints/bert.bccwj.network.epoch1
batch_size = 150
num_epochs = 50
learning_rate = 1e-4
warmup_proportion = 0.1
weight_decay = 0.01

[mask]
num_to_mask = 20
max_seq_len = 256
